---
title: 'STAT/MATH 495: Problem Set 03'
author: "Pei Gong"
date: '2017-09-26'
output:
  html_document:
    collapsed: no
    smooth_scroll: no
    toc: yes
    toc_depth: 2
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4.5)
# Load packages
library(tidyverse)
data1 <- read_csv("data/data1.csv")
data2 <- read_csv("data/data2.csv")
```


# Question
For both `data1` and `data2` tibbles (a tibble is a data frame with some
[metadata](https://blog.rstudio.com/2016/03/24/tibble-1-0-0#tibbles-vs-data-frames) attached):
* Find the splines model with the best out-of-sample predictive ability.
* Create a visualizaztion arguing why you chose this particular model.
* Create a visualizaztion of this model plotted over the given $(x_i, y_i)$ points for $i=1,\ldots,n=3000$.
* Give your estimate $\widehat{\sigma}$ of $\sigma$ where the noise component $\epsilon_i$ is distributed with mean 0 and standard deviation $\sigma$.

# Data 1
```{r, echo=TRUE, warning=FALSE, message=FALSE}
set.seed(88)
#randomly select a training set
data1_train <- data1%>%  
  sample_n(1500)
#form the test set 
data1_test <- data1 %>% 
  anti_join(data1_train, by="ID")
```

##Step 1:Fit model on training set 
```{r,echo=TRUE, warning=FALSE, message=FALSE}
data1_model_train<- smooth.spline(x=data1_train$x, y=data1_train$y,df=34)
data1_model_train_df <- data1_model_train %>% 
  broom::augment()
```

##Step 2:Take previoulsy fitted model and make predictions on the test set:
```{r,echo=TRUE}
test_predicts <- predict(data1_model_train, data1_test$x) %>% as.tibble()
y_hat <- test_predicts %>% pull(y)
data1_test1<-data1_test %>% mutate(y_hat)
```
##Step 3:Compute score
```{r,echo=TRUE}  
 Score_test<-data1_test1%>%
  summarise(MSE = mean((y - y_hat)^2)) %>% 
  mutate(RMSE = sqrt(MSE)) %>% pull(RMSE)
```
##Step 4:Cross Validation: Model on Test to predict Train (repeat step 1-3)
```{r}
data1_model_test<- smooth.spline(x=data1_test$x, y=data1_test$y,df=34)
data1_model_test_df <- data1_model_test %>% 
  broom::augment()
```

```{r}
#Predict the train using model fitted on the test set
train_predicts <- predict(data1_model_test, data1_train$x) %>% as.tibble()
y_hat <- train_predicts %>% pull(y)
data1_train1<-data1_train %>% mutate(y_hat)
```

```{r}
 Score_train<-data1_train1%>%
  summarise(MSE = mean((y - y_hat)^2)) %>% 
  mutate(RMSE = sqrt(MSE)) %>% pull(RMSE)
final_score<-(Score_test+Score_train)/2;final_score
```
##Step 5:generalizable functions
return_score is function designed for two-folds cross-validation. It takes the value of degree of freedom,the training set, the test set, and return the RMSE of the fitted training smooth.spline model on test set.
```{r, echo=TRUE}
return_score <- function(data_train,data_test,d_freedom){
  #Step 1: fitting model on train.
  data_model_train<- smooth.spline(x=data_train$x, y=data_train$y,df=d_freedom)
  data_model_train_df <- data_model_train %>% 
  broom::augment()  
  #step2: predict on test
  test_predicts <- predict(data_model_train, data_test$x) %>% as.tibble()
  y_hat <- test_predicts %>% pull(y)
  data_test1<-data_test %>% mutate(y_hat) # add y_hat as the 4th column
  #step3: compute score 
  Score_test<-data_test1%>%
  summarise(MSE = mean((y - y_hat)^2)) %>% 
  mutate(RMSE = sqrt(MSE)) %>% pull(RMSE)
  return(Score_test)
}

```

search_df is a function that loops through potential values of degree of freedom through the cross-validation process. search_df takes two datasets, and a upper limit range for degree of freedom and returns a filled matrix with two columns: the degree of freedom and its corresponding RMSE score.  
```{r}
search_df <-function(data_A,data_B,range){ 
   score_table<- matrix(ncol=1, nrow=range)
   for(i in c(1:range)){
     score1<-return_score(data_A,data_B,i)
     score2<-return_score(data_B,data_A,i)
     RSME_final<-0.5*(score1+score2)
     score_table[i]<- RSME_final
   }
   return(score_table)
}
```

##Step 6: why choose df=34, visualization of model,$\widehat{\sigma}$=RMSE=15.10558
* Create a visualizaztion arguing why you chose this particular model.
```{r,message=FALSE,warning=FALSE}
score_table<-search_df(data1_test,data1_train,100)
score_data1<-as.data.frame(score_table)
score_data1 <- score_data1 %>% 
  mutate(df=1:n())
ggplot(score_data1, aes(x=df, y=V1)) +
  geom_point()+  ggtitle("Plot#1:optimal degree of freedom for minimum value of RMSE for data1")
```

* Create a visualizaztion of this model plotted over the given $(x_i, y_i)$ points for $i=1,\ldots,n=3000$.
```{r}
data1_model<- smooth.spline(x=data1$x, y=data1$y,df=34)
data1_model_df <- data1_model %>% 
  broom::augment()
ggplot(data1_model_df,aes(x=x))+
  geom_point(aes(y=y))+
  geom_line(aes(y=.fitted),col="red",size=1)+
  ggtitle("Plot#2: goodness of fit for entire dataset1")
```
* Give your estimate $\widehat{\sigma}$ of $\sigma$ where the noise component $\epsilon_i$ is distributed with mean 0 and standard deviation $\sigma$.

$y_i$=f(x)+$\epsilon_i$

$y_i$=$\hat{y_i}$+$\epsilon_i$

$\epsilon_i$=$y_i$-$\hat{y_i}$

$\sigma^2$=$\frac{1}{n} \sum_{i=1}^n \epsilon_i^2$=MSE=$RMSE^2$=15.10558^2

$\widehat{\sigma}$=RMSE=15.10558

# Data 2: 5 folds

##Step 1:Divide the data into 5 subsets with 600 observations each
```{r}
set.seed(88)
#randomly select a training set 
data2_1<- data2%>%  
  sample_n(600)
#form the test set  
data2_anti1 <- data2 %>% 
  anti_join(data2_1, by="ID")
#perform the same for subset 2
data2_2<-data2_anti1 %>% 
  sample_n(600)
data2_anti12<-data2_anti1 %>% 
  anti_join(data2_2, by="ID") 
#perform the same for subset 3
data2_3<-data2_anti12 %>% 
  sample_n(600)
data2_anti123<-data2_anti12 %>% 
  anti_join(data2_3, by="ID")
#perform the same for subset 4
data2_4<-data2_anti123 %>% 
  sample_n(600)
data2_5<-data2_anti123 %>% 
  anti_join(data2_4, by="ID") 
```

##Step 2:For each subset, find its corresponding training set.  
###fold 1
```{r}
return_score(data2_anti1,data2_1,31)
```
###fold 2
```{r}
data2_train2 <- data2 %>% 
  anti_join(data2_2, by="ID")
return_score(data2_train2,data2_2,31)
```
###fold 3
```{r}
data2_train3 <- data2 %>% 
  anti_join(data2_3, by="ID")
return_score(data2_train3,data2_3,31)
```
###fold 4
```{r}
data2_train4 <- data2 %>% 
  anti_join(data2_4, by="ID")
return_score(data2_train4,data2_4,31)
```
###fold 5
```{r}
data2_train5 <- data2 %>% 
  anti_join(data2_5, by="ID")
return_score(data2_train5,data2_5,31)
```
##Step 3:Modify the search_df function so that it works for 5 folds. 

search_df_data2 takes a range, loop through the 5 folds, and return the average RMSE as the final score. 
```{r,warning=FALSE}
search_df_data2<-function(range){ 
   score_table<- matrix(ncol=1, nrow=range)
   for(i in c(1:range)){
     score1<-return_score(data2_anti1,data2_1,i)
     score2<-return_score(data2_train2,data2_2,i)
    score3<-return_score(data2_train3,data2_3,i)
    score4<-return_score(data2_train4,data2_4,i)
      score5<-return_score(data2_train5,data2_5,i)
     RSME_final<-0.2*(score1+score2+score3+score4+score5)
     score_table[i]<- RSME_final
     }
   return(score_table) 
   }
```

##Step 4:why choose df=31, visualization of model,$\widehat{\sigma}$=RMSE=24.91260
* Find the splines model with the best out-of-sample predictive ability.
  $$df=31$$
* Create a visualizaztion arguing why you chose this particular model.

```{r}
score_table2<-search_df_data2(100)
score_data2<-as.data.frame(score_table2)
score_data2 <- score_data2 %>% 
  mutate(x=1:n())
ggplot(score_data2, aes(x=x, y=V1)) +
  geom_point()+  ggtitle("Plot#3:optimal degree of freedom for minimum value of RMSE for data1")
```

* Create a visualizaztion of this model plotted over the given $(x_i, y_i)$ points for $i=1,\ldots,n=3000$.
```{r}
data2_model<- smooth.spline(x=data2$x, y=data2$y,df=31)
data2_model_df <- data2_model %>% 
  broom::augment()
ggplot(data2_model_df,aes(x=x))+
  geom_point(aes(y=y))+
  geom_line(aes(y=.fitted),col="red",size=1)+
  ggtitle("Plot#4: goodness of fit for entire dataset2")
```
Give your estimate $\widehat{\sigma}$ of $\sigma$ where the noise component $\epsilon_i$ is distributed with mean 0 and standard deviation $\sigma$.
$y_i$=f(x)+$\epsilon_i$

$y_i$=$\hat{y_i}$+$\epsilon_i$

$\epsilon_i$=$y_i$-$\hat{y_i}$

$\sigma^2$=$\frac{1}{n} \sum_{i=1}^n \epsilon_i^2$=MSE=$RMSE^2$=$24.91260^2$

$\widehat{\sigma}$=RMSE=24.91260